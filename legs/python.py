# Dedicated to the public domain under CC0: https://creativecommons.org/publicdomain/zero/1.0/.

import re

from argparse import Namespace
from pprint import pformat
from typing import *
from pithy.fs import add_file_execute_permissions
from pithy.io import *
from pithy.string_utils import render_template
from .defs import ModeTransitions
from .rules import Rule


def output_python3(path: str, patterns: Dict[str, Rule], mode_rule_names: Dict[str, List[str]], transitions: ModeTransitions,
  rule_descs: Dict[str, str], license: str, args: Namespace):

  py_patterns: List[str] = []
  for name, rule in patterns.items():
    py_pattern = rule.genRegex(flavor='py')
    py_patterns.append(f"\n    {name}=r'{py_pattern}',")

  py_modes: List[str] = []
  for mode, rule_names in sorted(mode_rule_names.items()):
    names_str = ''.join(f'\n      {n!r},' for n in rule_names)
    py_modes.append(f'\n    {mode}={{{names_str}}}')

  py_transitions: List[str] = [f'\n    ({a}, {b}) : ({c}, {d})' for (a, b), (c, d) in transitions.items()]

  with open(path, 'w', encoding='utf8') as f:
    src = render_template(template,
      license=license,
      rules_path=args.path,
      patterns=''.join(py_patterns),
      modes=''.join(py_modes),
      transitions=''.join(py_transitions),
      Name=args.type_prefix,
      rule_descs=pformat(rule_descs, indent=2),
    )
    f.write(src)
    if args.test:
      test_src = render_template(test_template)
      f.write(test_src)


template = r'''# ${license}
# This file was generated by legs from ${rules_path}.

from pithy.lex import Lexer, msg_for_match
from typing import Match, Optional


${Name}Token = Match[str]

lexer = Lexer(
  invalid='invalid',
  patterns=dict(${patterns}),
  modes=dict(${modes}),
  transitions={${transitions}})

rule_descs = ${rule_descs}

def diagnostic_for_token(token: ${Name}Token, prefix: str = '', msg: str = '', showMissingFinalNewline: bool = True) -> str:
  return diagnostic_for_pos(string=token.string, pos=token.start(), end=token.end(), prefix=prefix, msg=msg,
    showMissingFinalNewline=showMissingFinalNewline)

#def diagnostic_for_end(string: str, end: int, prefix: str = '', msg: str = '', showMissingFinalNewline: bool = true) -> str:
#  lineIdx = self.newlinePositions.count # TODO
#  newlinePos = newlinePositions.last
#  linePos = 0 if newlinePos is None else newlinePos + 1
#  return diagnostic(pos: endPos, linePos: linePos, lineIdx: lineIdx, prefix: prefix, msg: msg)

def diagnostic_for_pos(string: str, pos: int, end: Optional[int], prefix: str = '', msg: str = '',
  showMissingFinalNewline: bool = True) -> str:

  def diagLine(line: str, showReturnSymbol: bool) -> str:
    if line.endswith('\n'):
      if showReturnSymbol:
        return line[:-1] + '\u23CE\n' # RETURN SYMBOL.
      else:
        return line
    elif showMissingFinalNewline:
      return line + '\u23CE\u0353\n' # RETURN SYMBOL, COMBINING X BELOW.
    else:
      return line + '\n'

  def underline(line: str, col: int, end_col: int = -1) -> str:
    if col < 0: return ''
    indent = ' ' * (col + line.count('\t', 0, col) * 7) # assume tabs render as 8 spaces on console.
    if col < end_col:
      return indent + '~' * (end_col - col)
    else:
      return indent + '^'

  assert 0 <= pos < len(string)
  assert end is None or 0 <= end <= len(string)

  line_idx = string.count('\n', 0, pos) # number of newlines preceeding pos.
  line_start = string.rfind('\n', 0, pos) + 1 # rfind returns -1 for no match, happens to work perfectly.
  line_end = string.find('\n', pos)
  if line_end == -1: line_end = len(string)
  line = string[line_start:line_end]
  col = pos - line_start

  msgSpace = '' if (not msg or msg.startswith('\n')) else ' '
  prefix_colon = prefix + ':' if prefix else ''
  common = f'{prefix_colon}{line_idx+1}:{col_string(col)}'
  if end is not None:
    if end <= line_end: # single line.
      end_col = end - line_start
      under = underline(line, col, end_col)
      showRetSym = (end == line_end)
      return f'{common}-{col_string(end_col)}:{msgSpace}{msg}\n{diagLine(line, showRetSym)}{under}\n'
    else: # multiline.
      end_line_idx = string.count('\n', 0, end)
      end_line_start = string.rfind('\n', 0, end) + 1
      end_line_end = string.rfind('\n', end)
      if end_line_end == -1: end_line_end = len(string)
      end_line = string[end_line_start:end_line_end]
      endRetSym = (end == end_line_end)
      under = underline(line, col, len(line))
      endUnder = underline(end_line, 0, end_line_end - end)
      a = f'{common}--{endLineNum}:{col_string(end_col)}:{msgSpace}{msg}\n'
      b = f'{diagLine(line, true)}{under}â€¦\n'
      c = f'{diagLine(endLine, endRetSym)}{endUnder}\n'
      return '\(a)\(b)\(c)'
  else: # single line, zero width column.
    showRetSym = (pos == lineEnd - 1)
    return f'{common}:{msgSpace}{msg}\n{diagLine(line, showRetSym)}{underline(line, col)}\nSINGLE {end} {line_end}'


def col_string(col: int) -> str:
  return str(col + 1) if (col >= 0) else '?'
'''


test_template = r'''

# Legs test main.

def test(index: int, arg: str) -> None:
  name = f'arg{index}'
  print(f'\n{name}: {ployRepr(arg)}')
  for token in lexer.lex(arg):
    print(diagnostic_for_token(token, prefix=name, msg=rule_descs[token.lastgroup],
      showMissingFinalNewline=False), end='')

def ployRepr(string: str) -> str:
  r = ["'"]
  for char in string:
    if char == '\\': r.append('\\\\')
    elif char == "'": r.append("\\'")
    elif 0x20 <= ord(char) <= 0x7E: r.append(char)
    elif char == '\0': r.append('\\0')
    elif char == '\t': r.append('\\t')
    elif char == '\n': r.append('\\n')
    elif char == '\r': r.append('\\r')
    else: r.append(f'\\{hex(ord(char))};')
  r.append("'")
  return ''.join(r)

def main() -> None:
  from sys import argv
  for i, arg in enumerate(argv):
    if i == 0: continue
    test(index=i, arg=arg)

if __name__ == '__main__': main()
'''
